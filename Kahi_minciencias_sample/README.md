<center><img src="https://raw.githubusercontent.com/colav/colav.github.io/master/img/Logo.png"/></center>

# Kahi miniencias_sample plugin 
It is a Python plugin designed to process the Minciencias database, extracting and sampling works based on various criteria. This plugin allows you to filter and extract works related to authors, products, types, groups, institutions, categories, custom queries, and custom pipelines from the Minciencias database.

# Description
Features:
* Author-based Extraction: Extract works associated with specific authors.
* Product-based Extraction: Extract works based on product IDs using regular expressions.
* Group-based Extraction: Extract works associated with specific groups.
* Category-based Extraction: Extract works based on categories using regular expressions.
* Custom Queries: Apply custom queries to extract specific works.
* Custom Pipelines: Process custom aggregation pipelines to extract works.
* CVLAC Stage Processing: Process and extract CVLAC stage profiles for unique persons.
* GRUPLAC Groups Processing: Process and extract GRUPLAC groups data.

# Installation

## Dependencies
This require the data generated by the package Yuku https://github.com/colav/yuku

## Package
Write here how to install this plugin
usauly is 

`pip install kahi_miniencias_sample`


# Usage
This is an example of the work flow to the extraction,
take the section of the workflow you need to get your sample.

```
config:
  database_url: localhost
  log_database: kahi_saples_log
  log_collection: log
  profile: False
workflow:
  minciencias_sample:
    verbose: 1
    num_jobs: 20
    database_out:
      drop_database: True
      database_url: localhost
      database_name: minciencias_sample
      collection_names:
      - gruplac_production: gruplac_production_data
      - gruplac_groups: gruplac_groups_data
      - cvlac_stage: cvlac_stage
      - cvlac_stage_private: cvlac_stage_private
      - cvlac_data: cvlac_data
    database_in:
      database_url: localhost:27017
      database_name: yuku
      collection_names:
      - gruplac_production: gruplac_production_data
      - gruplac_groups: gruplac_groups_data
      - cvlac_stage: cvlac_stage
      - cvlac_stage_private: cvlac_stage_private
      - cvlac_data: cvlac_data
    authors: 
      - "0000177733" # Diego Restrepo
      - "0001385569" # Claudia Marcela Velez
      - "0000536237" # Gabriel Jaime Velez Cuartas
    products: # this have to be a compilable regex
      - 'ART-0000177733-1'   # el primer producto de Diego Restrepo
      - 'ART-0000536237-*'   # todos los productos (ART) de Gabriel Jaime Velez Cuartas
      - '.*-0000536237-.*'     # todos los typos de productos  de Cludia Marcela Velez (regex)
    groups:
      - "COL0008423" #Grupo de Fenomenolog√≠a de Interacciones Fundamentales (only id that starts wih COL is supported)
    categories: # this have to be a compilable regex
      - 'ART-ART_A2' #  there are like 80 types and it depends of the year of the dataset.
      - 'PE-*' # all the books
    custom_queries: # you have to build the mongodb query and it have to return always works
      - {"cod_grupo_gr": "COL0008423", "id_tipo_pd_med": "ART-ART_A2"} # products ART-ART_A2 of Gfif group
    custom_pipelines: # you have to build the mongodb pipeline and it have to return always works
      - [{"$match": { 
            "cod_grupo_gr": "COL0008423",
            "id_tipo_pd_med": "ART-ART_A2"
        }}]
```
Those parameters are not really needed in the workflow file, it is just for illustration.

save the file with a name like workflow.yml and run it with

```
kahi_run --workflow workflow.yml
```

# License
BSD-3-Clause License 

# Links
http://colav.udea.edu.co/



